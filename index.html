<!DOCTYPE html>
<html lang="en">
    <head>
        <title>Xiang Lisa Li </title>
        <meta http-equiv="content-type" content="text/html; charset=UTF-8">
        <meta charset="utf-8">
	    <meta property="og:title" content="Xiang Li" />
	    <meta property="og:image" content="https://xiangli1999.github.io/img/lisa.jpg" />
	    <meta http-equiv="X-UA-Compatible" content="IE=edge">
	    <meta name="author" content="Xiang Li">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
        <link rel="shortcut icon" type="image/png" href="favicon.ico"/>

        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
        <link rel="stylesheet" href="css/style.css">
        <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
        <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
    </head>
    <body>
    	<style>
		pre {
    		text-align: left;
    		white-space: pre-line;
  		}
		</style>
        <div class="container mt-5">
            <div class="row mb-3">
                <div class="col">
                    <h1>Xiang Lisa Li </h1>
                </div>
            </div>
            <div class="row">
                <div class="col-md-4 order-md-2">
                    <img src="img/lisa.jpeg" alt="Lisa" class="img-fluid rounded">
                </div>
                <div class="col-md-8 order-md-1">
                    <p>
                        Hi! I am a final year Ph.D. student at Stanford University, coadvised by <a href="https://cs.stanford.edu/~pliang" target="_blank">Percy Liang</a> and <a href="https://thashim.github.io/" target="_blank">Tatsunori Hashimoto</a>. 
                        My research is supported by Stanford Graduate Fellowship and Two Sigma PhD Fellowship. 
                    </p>
                    <p>  
                        
                        I work on developing methods to overcome structural limitations of language models. My research encompasses many stages of language model development, including architecture (Diffusion-LM), adaptation (Prefix-Tuning), self-supervision (GV-consistency), decoding (Contrastive Decoding) and evaluation (AutoBencher).   

                    </p>
                    <p>
                        Previously, I received undergraduate degrees from Johns Hopkins University, majoring in Computer Science and Applied Mathmatics and Statistics. I am fortunate to be advised by Prof. <a href="http://www.cs.jhu.edu/~jason/" target="_blank">Jason Eisner</a>. 
                    </p>
                    <p>
                        If you're interested in getting started in research and think it'd be useful to chat, please feel free to email me.
                    </p>
                    <p>
                        Email: xlisali [<a href="https://en.wikipedia.org/wiki/At_sign" target="_blank">at</a>] stanford.edu
                    </p>
                    <p>
                        Links:
                        [<a href="https://github.com/XiangLi1999" target="_blank">Github</a>] [<a href="https://scholar.google.com/citations?user=nzA4P0oAAAAJ&hl=en" target="_blank">Google Scholar</a>]
                    </p>
                </div>
            </div>
            <div class="row">
                <div class="col">
                    
                    
                </div>
            </div>

            <!-- <div class="row">
                <div class="col">
                    <h2>Recent News</h2>
                    <ul>
                    	<li>
                            (8/2022) Gave a talk at Google Language Group about Diffusion-LM 
                        </li>
                        <li>
                            (8/2022) Gave a talk at Meta Westcoast NLP about Diffusion-LM 
                        </li>
                        <li>
                            (7/2022) Gave a talk at Google Reasoning Reading Group about Diffusion-LM 
                        </li>
                        <li>
                            (7/2022) Gave a talk at Stanford NLP lunch about Diffusion-LM 
                        </li>
                        <li>
                            (4/2022) Gave a talk at NUS NLP Seminar about Ensemble and Cocktail paper
                        </li>
                        <li>
                            (6/2021) Gave a talk at USC ISI NL Seminar about prefix-tuning
                        </li>
                        <li>
                            (5/2021) Present prefix-tuning at NLP Highlights Podcast
                        </li>
                        <li>
                            (3/2021) Gave a talk at Google NLP Reading group about Prefix-tuning
                        </li>
                    </ul>
                </div>
            </div> -->
            
            <hr>
            <div class="row" id="publications">
                <div class="col">
                    <h2>Selected Publications </h2>
                    <p>(for full publication list please checkout my [<a href="https://scholar.google.com/citations?user=nzA4P0oAAAAJ&hl=en" target="_blank">Google Scholar</a>])

                    <ul>

<li>

                            <a href="pdf/diffusion-lm.pdf" target="_blank">
                                <b>Diffusion-LM Improves Controllable Text Generation</b>
                            </a>
                            <br/>
                            <b>Xiang Lisa Li</b>, John Thickstun, Ishaan Gulrajani, Percy Liang, Tatsunori B. Hashimoto
                            <br/>
                            In <a href="" target="_blank">
                                <b>
                                    Neurips 2022 </b></a>
                            <br/>

                            [<a href="#" onclick="$('#diffusion_lm_bib').toggle();return false;">bib</a>]
                            [<a href="#" onclick="$('#diffusion_lm_abstract').toggle();return false;">abstract</a>]
                            [<a href="https://arxiv.org/pdf/2205.14217.pdf" target="_blank">arxiv</a>]
                            <!-- [<a href="" target="_blank">dataset</a>] -->
                            <div id="diffusion_lm_abstract" class="abstract" style="display:none;">
                                <p>
                                    Controlling the behavior of language models (LMs) without re-training is a major open problem in natural language generation. While recent works have demonstrated successes on controlling simple sentence attributes (e.g., sentiment), there has been little progress on complex, fine-grained controls (e.g., syntactic structure). To address this challenge, we develop a new non-autoregressive language model based on continuous diffusions that we call Diffusion-LM. Building upon the recent successes of diffusion models in continuous domains, Diffusion-LM iteratively denoises a sequence of Gaussian vectors into word vectors, yielding a sequence of intermediate latent variables. The continuous, hierarchical nature of these intermediate variables enables a simple gradient-based algorithm to perform complex, controllable generation tasks. We demonstrate successful control of Diffusion-LM for six challenging fine-grained control tasks, significantly outperforming prior work.
                                </p>
                            </div>
                            <div id="diffusion_lm_bib" class="bib" style="display:none;">
                                <pre>
                                @article{Li-2022-DiffusionLM,
                                title={Diffusion-LM Improves Controllable Text Generation},
                                author={Xiang Lisa Li and John Thickstun and Ishaan Gulrajani and Percy Liang and Tatsunori Hashimoto},
                                journal={ArXiv},
                                year={2022},
                                volume={abs/2205.14217}
                            }
                                </pre>
                            </div>
                        </li>
                        <br/>


                        <!-- ================= -->

                        <li>

                            <a href="pdf/prefix_tuning.pdf" target="_blank">
                                <b>Prefix-Tuning: Optimizing Continuous Prompts for Generation</b>
                            </a>
                            <br/>
                            <b>Xiang Lisa Li</b>
                            and Percy Liang

                            <br/>
                            In <a href="" target="_blank">
                                <b>
                                    ACL 2021 </b></a>
                            <br/>

                
                           <!--   <b style="color:#FF0000";> Most cited paper in ACL 2021 </b> <br/> -->
                            [<a href="#" onclick="$('#acl2021_bib').toggle();return false;">bib</a>]
                            [<a href="#" onclick="$('#acl2021_abstract').toggle();return false;">abstract</a>]
                            <!-- [<a href="" target="_blank">dataset</a>] -->
                            <div id="acl2021_abstract" class="abstract" style="display:none;">
                                <p>
                                    Fine-tuning is the de facto way of leveraging large pretrained language models for downstream tasks. However, fine-tuning modifies all the language model parameters and therefore necessitates storing a full copy for each task. In this paper, we propose prefix-tuning, a lightweight alternative to fine-tuning for natural language generation tasks, which keeps language model parameters frozen and instead optimizes a sequence of continuous task-specific vectors, which we call the prefix. Prefix-tuning draws inspiration from prompting for language models, allowing subsequent tokens to attend to this prefix as if it were ``virtual tokens''. We apply prefix-tuning to GPT-2 for table-to-text generation and to BART for summarization. We show that by learning only 0.1% of the parameters, prefix-tuning obtains comparable performance in the full data setting, outperforms fine-tuning in low-data settings, and extrapolates better to examples with topics that are unseen during training.
                                </p>
                            </div>
                            <div id="acl2021_bib" class="bib" style="display:none;">
                                <pre>
                                @inproceedings{li-liang-2021-prefix,
                                    title = "Prefix-Tuning: Optimizing Continuous Prompts for Generation",
                                    author = "Li, Xiang Lisa  and
                                      Liang, Percy",
                                    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
                                    month = aug,
                                    year = "2021",
                                    address = "Online",
                                    publisher = "Association for Computational Linguistics",
                                    url = "https://aclanthology.org/2021.acl-long.353",
                                    doi = "10.18653/v1/2021.acl-long.353",
                                    pages = "4582--4597",
                                }
                                </pre>
                            </div>
                        </li>
                        <br/>



                        <li>
    <a href="https://arxiv.org/pdf/2310.01846" target="_blank">
        <b>Benchmarking and Improving Generator-Validator Consistency of Language Models</b>
    </a>
    <br/>
    <b>Xiang Lisa Li</b>, Vaishnavi Shrivastava, Siyan Li, 
    Tatsunori Hashimoto, and Percy Liang
    <br/>
    In <a href="" target="_blank">
        <b>ICLR 2023</b></a>
    <br/>

    [<a href="#" onclick="$('#iclr2023_bib').toggle();return false;">bib</a>]
    [<a href="#" onclick="$('#iclr2023_abstract').toggle();return false;">abstract</a>]

    <div id="iclr2023_abstract" class="abstract" style="display:none;">
        <p>
            As of September 2023, ChatGPT correctly answers "what is 7+8" with 15, but when asked "7+8=15, True or False" it responds with "False". This inconsistency between generating and validating an answer is prevalent in language models (LMs) and erodes trust. In this paper, we propose a framework for measuring the consistency between generation and validation (which we call generator-validator consistency, or GV-consistency), finding that even GPT-4, a state-of-the-art LM, is GV-consistent only 76% of the time. To improve the consistency of LMs, we propose to finetune on the filtered generator and validator responses that are GV-consistent, and call this approach consistency fine-tuning. We find that this approach improves GV-consistency of Alpaca-30B from 60% to 93%, and the improvement extrapolates to unseen tasks and domains (e.g., GV-consistency for positive style transfers extrapolates to unseen styles like humor). In addition to improving consistency, consistency fine-tuning improves both generator quality and validator accuracy without using any labeled data. Evaluated across 6 tasks, including math questions, knowledge-intensive QA, and instruction following, our method improves the generator quality by 16% and the validator accuracy by 6.3% across all tasks.
        </p>
    </div>
    
    <div id="iclr2023_bib" class="bib" style="display:none;">
        <pre>
        @inproceedings{li2023gvconsistency,
            title = "Benchmarking and Improving Generator-Validator Consistency of Language Models",
            author = "Li, Xiang Lisa and Shrivastava, Vaishnavi and Li, Siyan and 
                      Hashimoto, Tatsunori and Liang, Percy",
            booktitle = "Proceedings of the International Conference on Learning Representations",
            month = apr,
            year = "2023",
            address = "Online",
            publisher = "International Conference on Learning Representations",
            url = "https://arxiv.org/pdf/2310.01846",
        }
        </pre>
    </div>
</li>
<br/>

                        <!-- ================= -->


<li>
    <a href="https://arxiv.org/pdf/2210.15097" target="_blank">
        <b>Contrastive Decoding: Open-ended Text Generation as Optimization</b>
    </a>
    <br/>
    <b>Xiang Lisa Li</b>, Ari Holtzman, Daniel Fried, Percy Liang, Jason Eisner, Tatsunori Hashimoto, Luke Zettlemoyer, and Mike Lewis
    <br/>
    In <a href="" target="_blank">
        <b>ACL 2023</b></a>
    <br/>

    [<a href="#" onclick="$('#acl2023_bib').toggle();return false;">bib</a>]
    [<a href="#" onclick="$('#acl2023_abstract').toggle();return false;">abstract</a>]

    <div id="acl2023_abstract" class="abstract" style="display:none;">
        <p>
            Given a language model (LM), maximum probability is a poor decoding objective for open-ended generation, because it produces short and repetitive text. On the other hand, sampling can often produce incoherent text that drifts from the original topics. We propose contrastive decoding (CD), a reliable decoding approach that optimizes a contrastive objective subject to a plausibility constraint. The contrastive objective returns the difference between the likelihood under a large LM (called the expert, e.g., OPT-13B) and a small LM (called the amateur, e.g., OPT-125M), and the constraint ensures that the outputs are plausible. CD is inspired by the fact that the failures of larger LMs (e.g., repetition, incoherence) are even more prevalent in smaller LMs, and that this difference signals which texts should be preferred. CD requires zero additional training, and produces higher quality text than decoding from the larger LM alone. It also works across model scales (OPT-13B and GPT2-1.5B) and significantly outperforms four strong decoding algorithms (e.g., nucleus, top-k) in automatic and human evaluations across wikipedia, news, and story domains.
        </p>
    </div>
    
    <div id="acl2023_bib" class="bib" style="display:none;">
        <pre>
        @inproceedings{li2023contrastivedecoding,
            title = "Contrastive Decoding: Open-ended Text Generation as Optimization",
            author = "Li, Xiang Lisa and Holtzman, Ari and Fried, Daniel and 
                      Liang, Percy and Eisner, Jason and Hashimoto, Tatsunori and 
                      Zettlemoyer, Luke and Lewis, Mike",
            booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics",
            month = jul,
            year = "2023",
            address = "Toronto, Canada",
            publisher = "Association for Computational Linguistics",
            url = "https://arxiv.org/pdf/2210.15097",
        }
        </pre>
    </div>
</li>
<br/>


<li>
    <a href="https://arxiv.org/abs/2407.08351" target="_blank">
        <b>AutoBencher: Towards Declarative Benchmark Construction</b>
    </a>
    <br/>
    <b>Xiang Lisa Li</b>, Farzaan Kaiyom, Evan Zheran Liu, Yifan Mai, Percy Liang, and Tatsunori Hashimoto
    <br/>
    <i>ArXiv 2024</i>
    <br/>

    [<a href="#" onclick="$('#autobencher_bib').toggle();return false;">bib</a>]
    [<a href="#" onclick="$('#autobencher_abstract').toggle();return false;">abstract</a>]

    <div id="autobencher_abstract" class="abstract" style="display:none;">
        <p>
            We present AutoBencher, a declarative framework for automatic benchmark construction, and use it to scalably discover novel insights and vulnerabilities of existing language models. Concretely, given a few desiderata of benchmarks (e.g., question difficulty, topic salience), we operationalize each desideratum and cast benchmark creation as an optimization problem. Specifically, we experiment with two settings with different optimization objectives: (i) for capability evaluation, we declare the goal of finding a salient, difficult dataset that induces novel performance patterns; (ii) for safety evaluation, we declare the goal of finding a dataset of unsafe prompts that existing LMs fail to decline. To tackle this type of optimization problem, we propose to use a language model to automatically construct datasets and iteratively revise the dataset to optimize for the declared desiderata. We use AutoBencher (powered by GPT-4) to create datasets for math, multilinguality, knowledge, and safety. The scalability of AutoBencher allows it to test fine-grained categories and tail knowledge, creating datasets that are on average 27% more novel and 22% more difficult than existing benchmarks. AutoBencher also helps identify specific gaps not captured by existing benchmarks: e.g., Gemini-Pro has knowledge gaps on Permian Extinction and Fordism while GPT-4 fails to decline harmful requests about cryptocurrency scams.
        </p>
    </div>
    
    <div id="autobencher_bib" class="bib" style="display:none;">
        <pre>
        @article{li2024autobencher,
            title = "AutoBencher: Towards Declarative Benchmark Construction",
            author = "Li, Xiang Lisa and Kaiyom, Farzaan and Liu, Evan Zheran and 
                      Mai, Yifan and Liang, Percy and Hashimoto, Tatsunori",
            journal = "arXiv preprint arXiv:2407.08351",
            year = "2024",
            url = "https://arxiv.org/abs/2407.08351",
        }
        </pre>
    </div>
</li>
<br/>


                        <li>
                            <a href="pdf/control_gen.pdf" target="_blank">
                                <b>Posterior Control of Blackbox Generation</b>
                            </a>
                            <br/>
                            <b>Xiang Lisa Li</b>
                            and <a href="http://rush-nlp.com" target="_blank">Alexander Rush</a>

                            <br/>
                            In <a href="https://acl2020.org" target="_blank">
                                <b>
                                    Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL) </b></a>, 2020.
                            <br/>

                

                            [<a href="#" onclick="$('#acl2020_bib').toggle();return false;">bib</a>]
                            [<a href="#" onclick="$('#acl2020_abstract').toggle();return false;">abstract</a>]
                            [<a href="pdf/control_gen_app.pdf" target="_blank">appendix</a>]
                            <!-- [<a href="" target="_blank">dataset</a>] -->
                            <div id="acl2020_abstract" class="abstract" style="display:none;">
                                <p>
                                    Text generation often requires high-precision output that obeys task-specific rules. This fine-grained control is difficult to enforce with off-the-shelf deep learning models. In this work, we consider augmenting neural generation models with discrete control states learned through a structured latent-variable approach. Under this formulation, task-specific knowledge can be encoded through a range of rich, posterior constraints that are effectively trained into the model. This approach allows users to ground internal model decisions based on prior knowledge, without sacrificing the representational power of neural generative models. Experiments consider applications of this approach for text generation. We find that this method improves over standard benchmarks, while also providing fine-grained control.
                                </p>
                            </div>
                            <div id="acl2020_bib" class="bib" style="display:none;">
                                <pre>
                                @inproceedings{li-rush-2020,
                                  author =      {Xiang Lisa Li and Alexander M. Rush},
                                  title =       {Posterior Control of Blackbox Generation},
                                  booktitle =   {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
                                  year =        {2020},
                                  month =       jul,
                                  address =     {Online},
                                  url =         {<a href="https://xiangli1999.github.io/pdf/control_gen.pdf">https://xiangli1999.github.io/pdf/control_gen.pdf</a>}
                                }
                                </pre>
                            </div>
                        </li>
                        <br/>



                        <li>
                            <a href="pdf/VIB.pdf" target="_blank">
                                <b>Specializing Word Embeddings (for Parsing) by Information Bottleneck</b>
                            </a>
                            <br/>
                            <b>Xiang Lisa Li</b>
                            and <a href="http://www.cs.jhu.edu/~jason/" target="_blank">Jason Eisner</a>
                            <br/>
                            In <a href="https://www.emnlp-ijcnlp2019.org" target="_blank">
                                <b>
                                    Conference on Empirical Methods in Natural Language Processing
                                    (EMNLP-IJCNLP)</b></a>, 2019.
                            	<br/>

                            <b style="color:#FF0000";> Best Paper Award at EMNLP-IJCNLP 2019 </b> <br/>
                            [<a href="#" onclick="$('#emnlp2019_bib').toggle();return false;">bib</a>]
                            [<a href="#" onclick="$('#emnlp2019_abstract').toggle();return false;">abstract</a>]
                            [<a href="pdf/VIB-supp.pdf" target="_blank">appendix</a>]
                            <!-- [<a href="" target="_blank">dataset</a>] -->
                            <div id="emnlp2019_abstract" class="abstract" style="display:none;">
                                <p>
                                    Pre-trained word embeddings like ELMo and BERT contain rich syntactic 
  									and semantic information, resulting in state-of-the-art performance on 
  									various tasks.  We propose a very fast variational information bottleneck
  									(VIB) method to nonlinearly compress these embeddings, keeping only the
  									information that helps a discriminative parser. We compress each word
  									embedding to either a discrete tag or a continuous vector. 
  									In the discrete version, our automatically compressed tags form an 
  									alternative tag set: we show experimentally that our tags capture most 
  									of the information in traditional POS tag annotations, but our tag 
  									sequences can be parsed more accurately at the same level of tag granularity.
   									In the continuous version, we show experimentally that moderately compressing 
   									the word embeddings by our method yields a more accurate parser in 8 of 9 
   									languages, unlike simple dimensionality reduction.
                                </p>
                            </div>
                            <div id="emnlp2019_bib" class="bib" style="display:none;">
                            	<pre>
								@inproceedings{li-eisner-2019,
								  author =      {Xiang Lisa Li and Jason Eisner},
								  title =       {Specializing Word Embeddings (for Parsing) by
								                 Information Bottleneck},
								  booktitle =   {Proceedings of the 2019 Conference on Empirical
								                 Methods in Natural Language Processing and 9th
								                 International Joint Conference on Natural Language
								                 Processing},
								  year =        {2019},
								  month =       nov,
								  address =     {Hong Kong},
								  url =         {<a href="http://cs.jhu.edu/~jason/papers/#li-eisner-2019">http://cs.jhu.edu/~jason/papers/#li-eisner-2019</a>}
								}
								</pre>
                            </div>
                        </li>
                        <br/>
                       <!--  <li>
                            <a href="pdf/punctuation.pdf" target="_blank">
                                <b>A Generative Model for Punctuation in Dependency Trees</b>
                            </a>
                            <br/>
                            <b>Xiang Lisa Li </b> and
                            <a href="http://www.cs.jhu.edu/~wdd/" target="_blank">Dingquan Wang</a> and
                            <a href="http://www.cs.jhu.edu/~jason/" target="_blank">Jason Eisner</a>.
                            <br/>
                            In <a href="https://www.transacl.org/ojs/index.php/tacl" target="_blank">
                                <b> Transactions of the Association for Computational
                 					Linguistics (TACL)</b></a>, 2019.
                            <br/>
                            [<a href="#" onclick="$('#tacl2019_bib').toggle();return false;">bib</a>]
                            [<a href="#" onclick="$('#tacl2019_abstract').toggle();return false;">abstract</a>]
                            [<a href="https://arxiv.org/abs/1906.11298" target="_blank">arxiv</a>]

                            <div id="tacl2019_abstract" class="abstract" style="display:none;">
                                <p>
                                    Treebanks traditionally treat punctuation marks as ordinary words, but linguists have suggested that a tree’s “true” punctuation marks are not observed (Nunberg, 1990). These latent “underlying” marks serve to delimit or separate constituents in the syntax tree. When the tree’s yield is rendered as a written sentence, a string rewriting mechanism transduces the underlying marks into “surface” marks, which are part of the observed (surface) string but should not be regarded as part of the tree. We formalize this idea in a generative model of punctuation that admits efficient dynamic programming. We train it without observing the underlying marks, by locally maximizing the incomplete data likelihood (similarly to EM). When we use the trained model to reconstruct the tree’s underlying punctuation, the results appear plausible across 5 languages, and in particular, are consistent with Nunberg’s analysis of English. We show that our generative model can be used to beat baselines on punctuation restoration. Also, our reconstruction of a sentence’s underlying punctuation lets us appropriately render the surface punctuation (via our trained underlying-to-surface mechanism) when we syntactically transform the sentence.
                                </p>
                            </div>

                            <div id="tacl2019_bib" class="bib" style="display:none;">
                            	<pre>
								@inproceedings{li-eisner-2019,
								  author =      {Xiang Lisa Li and Jason Eisner},
								  title =       {Specializing Word Embeddings (for Parsing) by
								                 Information Bottleneck},
								  booktitle =   {Proceedings of the 2019 Conference on Empirical
								                 Methods in Natural Language Processing and 9th
								                 International Joint Conference on Natural Language
								                 Processing},
								  year =        {2019},
								  month =       nov,
								  address =     {Hong Kong},
								  url =         {<a href="http://cs.jhu.edu/~jason/papers/#li-eisner-2019">http://cs.jhu.edu/~jason/papers/#li-eisner-2019</a>}
								}
								</pre>
                            </div>

                        </li> -->
                    </ul>
<br/>

                </div>
            </div>
            			<hr>
            <div class="row">
                <div class="col">
                    <h2>Honors & Awards</h2>
                    <ul>
                        <li>
                            (April. 2023)
                             Two Sigma PhD Fellowship
                            <br/>
                        </li>


                        <li>
                            (Sep. 2020)
                            Stanford Graduate Fellowship
                            <br/>
                        </li>

                        <li>
                            (May. 2020)
                            Outstanding Senior Award 
                            <br/>
                        </li>

                        <li>
                            (Dec. 2019)
                            <a href="https://cra.org/about/awards/outstanding-undergraduate-researcher-award/" target="_blank"> Outstanding Undergraduate Researcher Award  </a> (Computing Research Association) 
                        </li>
                        <li>
                            (Nov. 2019)
                            Best Paper Award at EMNLP-IJCNLP
                            <br/>
                        </li>

                    </ul>
                </div>
            </div>

            <hr>
             <div class="row">
                <div class="col">
                    <h2>Teaching Experience</h2>
                    <ul>
                        <li>
                            (Spring 2023) TA @ CS 224U at Stanford
                        </li>
                        <li>
                            (Winter 2023) TA @ CS 224N at Stanford
                        </li>
                        <li>
                            (Spring 2020) TA @ Introduction to Statistics (AMS 553.430/630)
                        </li>
                    	<li>
                            (Spring 2019) TA @ Introduction to Probability (AMS 553.420/620)
                        </li>
                        <li>
                        	(Fall 2018) TA @ Introduction to Probability (AMS 553.420/620)
                        </li>
                        <li>
                        	(Spring 2017) TA @ Introduction to Probability (AMS 553.420/620)
                        </li>
                        <li>
                        	(Fall 2017) TA @ Introduction to Probability (AMS 553.420/620)
                        </li>

                        <small>
                        	Interestingly, a perpetual prob TA is switching to stats...  Hope we can have fun in 430 :)
                        </small>
                  
                    </ul>
                </div>
            </div>

            <footer class="pt-2 my-md-2 pt-md-2 border-top">
                <div class="row justify-content-center">
                    <div class="col-6 col-md text-left align-self-center">
                        <p class="h5 text-muted">
                            Lisa, 2024
                        </p>
                    </div>
                </div>
            </footer>
        </div>
	    <script>
            (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
             (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
                                     m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
                                    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
            ga('create', 'UA-51640218-1', 'auto');
            ga('send', 'pageview');
        </script>
    </body>
</html>
